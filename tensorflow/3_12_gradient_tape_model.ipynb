{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3.12_gradient_tape_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMkmScR3Pp10L+5u9R3IYAB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lala991204/DL-self-study/blob/master/tensorflow/3_12_gradient_tape_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "6OslX796B1GS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHIjpE0i_400",
        "outputId": "397afb74-2214-4d9e-caad-64cd13655747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train / x_train.max()\n",
        "x_test = x_test / x_test.max()\n",
        "\n",
        "# 모델 정의\n",
        "model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "        tf.keras.layers.Dense(256, activation='relu'),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(10, activation='softmax'),\n",
        "])\n",
        "\n",
        "# 손실함수 정의\n",
        "loss_function =  tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "\n",
        "# optimizer 정의\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# 기록을 위한 Metirc 정의\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
        "valid_loss = tf.keras.metrics.Mean(name='valid_loss')\n",
        "valid_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='valid_accuracy')\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "# 배치 생성 함수\n",
        "def get_batches(x, y, batch_size=32):\n",
        "    for i in range(int(x.shape[0] // batch_size)):\n",
        "        x_batch = x[i * batch_size:(i+1) * batch_size]\n",
        "        y_batch = y[i * batch_size:(i+1) * batch_size]\n",
        "        yield(np.asarray(x_batch), np.asarray(y_batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow가 2.0 version으로 update되면서 지연 실헹(lazy execution) 모드에서 즉시 실행(eager execution) 모드가 기본으로 활성화되도록 변경되었다. 함수에 @tf.function 데코레이터를 붙여주면 텐서플로가 계산 그래프를 변환하여 지연 실행 모드로 처리된다."
      ],
      "metadata": {
        "id": "VcEj2GBFAQrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    # GradientTape 적용\n",
        "    with tf.GradientTape() as tape:\n",
        "        # 예측\n",
        "        prediction = model(images, training=True)\n",
        "        # 손실\n",
        "        loss = loss_function(labels, prediction)\n",
        "        # 미분(gradient) 값 계산\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "        # optimizer 적용\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))    # 이전에 구한 gradient와 trainable_variables를 zip으로 묶어 대입해 gradient 갱신 \n",
        "        # loss, accuracy 계산\n",
        "        train_loss(loss)\n",
        "        train_accuracy(labels, prediction)\n",
        "\n",
        "@tf.function\n",
        "def valid_step(images, labels):\n",
        "    # 예측\n",
        "    prediction = model(images, training=False)     # gradient가 갱신되지 않도록 설정함.\n",
        "    # 손실\n",
        "    loss = loss_function(labels, prediction)\n",
        "\n",
        "    # loss, accuracy \n",
        "    valid_loss(loss)\n",
        "    valid_accuracy(labels, prediction)"
      ],
      "metadata": {
        "id": "LvbQ91aEBvm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 초기화 코드\n",
        "train_loss.reset_states()\n",
        "train_accuracy.reset_states()\n",
        "valid_loss.reset_states()\n",
        "valid_accuracy.reset_states()\n",
        "\n",
        "# epoch 반복\n",
        "for epoch in range(5):\n",
        "    # batch별 순회\n",
        "    for images, labels in get_batches(x_train, y_train):\n",
        "        # train_step\n",
        "        train_step(images, labels)\n",
        "\n",
        "    for images, labels in get_batches(x_test, y_test):\n",
        "        # valid_step\n",
        "        valid_step(images, labels)\n",
        "\n",
        "    # result\n",
        "    metric_template = 'epoch: {}, loss: {:.4f}, acc: {:.2f}%, val_loss:{:.4f}, val_acc: {:.2f}%'\n",
        "    print(metric_template.format(epoch+1, train_loss.result(), train_accuracy.result()*100, \\\n",
        "                                 valid_loss.result(), valid_accuracy.result()*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMfxQm4eC0AN",
        "outputId": "5a40c86e-411a-4b8b-fa2f-122912b29518"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 0.0475, acc: 98.58%, val_loss:0.1124, val_acc: 96.94%\n",
            "epoch: 2, loss: 0.0434, acc: 98.65%, val_loss:0.1018, val_acc: 97.22%\n",
            "epoch: 3, loss: 0.0393, acc: 98.76%, val_loss:0.0943, val_acc: 97.41%\n",
            "epoch: 4, loss: 0.0363, acc: 98.84%, val_loss:0.0943, val_acc: 97.52%\n",
            "epoch: 5, loss: 0.0339, acc: 98.92%, val_loss:0.0971, val_acc: 97.55%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OPfAQk6MEUsR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}