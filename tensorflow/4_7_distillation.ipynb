{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4.7_distillation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPDJnZ/XCIYeUkxbelPBryV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lala991204/DL-self-study/blob/master/tensorflow/4_7_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "87N3oJIUmcDv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파라미터 개수가 많은 큰 모델이 선생님이 되어 크기가 작은 모델을 가르치는 개념으로 Knowledge Distillation이라 부름. 큰 모델의 예측과 작은 모델의 예측의 오차(distillation)와 작은 모델의 손실함수(student loss)를 줄여 나가는 방향으로 작은 모델의 파라미터를 최적화함."
      ],
      "metadata": {
        "id": "ykKuzaeRwP1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 파라미터 설정\n",
        "t_ephoc = 5      # @param {type:\"slider\", min:1, max:100, step:1}\n",
        "s_ephoc = 10     # @param {type:\"slider\", min:1, max:100, step:1}\n",
        "learning_rate = 0.01\n",
        "batch_size = 64  # @param [32, 64, 128, 256] {type:\"raw\"} \n",
        "temperature = 3  # @param {type:\"slider\", min:1, max:10, step:1}\n",
        "alpha = 0.5      # @param {type:\"slider\", min:0.1, max:0.9, step:0.1}"
      ],
      "metadata": {
        "id": "U2vVXu6lnGVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# mnist dataset 가져오기\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train = x_train.astype(\"float32\")/255.0\n",
        "x_train = np.reshape(x_train, (-1, 28, 28, 1))     # 배치 사이즈가 들어갈 축 추가\n",
        "\n",
        "x_test = x_test.astype(\"float32\")/255.0\n",
        "x_test = np.reshape(x_test, (-1, 28, 28, 1))\n",
        "\n",
        "\n",
        "# teacher model(비교적 복잡한 모델 구성)\n",
        "i = tf.keras.Input(shape=(28, 28, 1))\n",
        "out = tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same')(i)\n",
        "out = tf.keras.layers.LeakyReLU(alpha=0.2)(out)\n",
        "out = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding=\"same\")(out)\n",
        "out = tf.keras.layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same')(out)\n",
        "out = tf.keras.layers.Flatten()(out)\n",
        "out = tf.keras.layers.Dense(10)(out)\n",
        "t_model = tf.keras.Model(inputs=[i], outputs=[out])\n",
        "\n",
        "t_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFotKY0Jn49C",
        "outputId": "ef9c9bfa-edc1-4025-d6df-2139a33dc146"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 14, 14, 256)       2560      \n",
            "                                                                 \n",
            " leaky_re_lu (LeakyReLU)     (None, 14, 14, 256)       0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 14, 14, 256)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 7, 7, 512)         1180160   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                250890    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,433,610\n",
            "Trainable params: 1,433,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# student model(단순한 구조)\n",
        "i = tf.keras.Input(shape=(28, 28, 1)) \n",
        "out = tf.keras.layers.Flatten()(i)\n",
        "out = tf.keras.layers.Dense(28)(out)\n",
        "out = tf.keras.layers.Dense(10)(out)\n",
        "\n",
        "s_model_1 = tf.keras.Model(inputs=[i], outputs=[out])\n",
        "s_model_2 = tf.keras.models.clone_model(s_model_1)       # 성능 비교를 위해 모델 복제\n",
        "\n",
        "s_model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qi-eH3RIo9ih",
        "outputId": "71cd16da-ac96-437c-9f9d-666e40ec36a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 28)                21980     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                290       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 22,270\n",
            "Trainable params: 22,270\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "파라미터가 teacher model의 약 1/70에 불과함"
      ],
      "metadata": {
        "id": "vJYpMPvtxUFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# teacher model\n",
        "t_model.compile(tf.keras.optimizers.Adam(learning_rate),\n",
        "                tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "# student model(distillation 적용)\n",
        "s_model_1.compile(tf.keras.optimizers.Adam(learning_rate),\n",
        "                  tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "# 비교 model(distillation 미적용)\n",
        "s_model_2.compile(tf.keras.optimizers.Adam(learning_rate),\n",
        "                  tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "\n",
        "t_model.fit(x_train, y_train, batch_size = batch_size, epochs = t_ephoc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-uFUeNGpWH4",
        "outputId": "70b11afd-d7f8-4622-e5d1-ec9a6bb4f498"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 722s 769ms/step - loss: 0.5496 - sparse_categorical_accuracy: 0.9208\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 596s 635ms/step - loss: 13.8130 - sparse_categorical_accuracy: 0.9372\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 545s 581ms/step - loss: 4.3400 - sparse_categorical_accuracy: 0.9617\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 547s 583ms/step - loss: 7.9766 - sparse_categorical_accuracy: 0.9581\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 545s 581ms/step - loss: 9.8430 - sparse_categorical_accuracy: 0.9635\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f46d8d79e50>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "teacher model의 경우 3 epoch만에 약 96%의 정확도 보임."
      ],
      "metadata": {
        "id": "VJy1V3gwxeKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## 다음은 Knowledge Distillation 학습에 필요한 loss들이다.\n",
        "# student 손실함수\n",
        "s_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# distillation 손실함수\n",
        "d_loss = tf.keras.losses.KLDivergence()    \n",
        "\n",
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATsoKNhfrBRs",
        "outputId": "658b7e41-4f93-47d0-b495-81cbde9257e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "참고로, KLDivergence는 서로 다른 두 개의 확률분포를 비교하여 유사성을 측정하는 지표이며, 서로 유사할수록 값이 작아짐."
      ],
      "metadata": {
        "id": "UlhR8yTTx7HV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_count = x_train.shape[0]//batch_size         # 총 배치의 개수\n",
        "opt = tf.keras.optimizers.Adam(learning_rate)\n",
        "for e in range(s_ephoc):\n",
        "    for _ in range(batch_count):         # 배치별로 각각의 loss 계산\n",
        "        batch_num = np.random.randint(0, x_train.shape[0], size=batch_size)\n",
        "        t_pred = t_model.predict(x_train[batch_num])\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            s_pred_1 = s_model_1(x_train[batch_num])\n",
        "            student_loss = s_loss(y_train[batch_num], s_pred_1)\n",
        "            distillation_loss = d_loss(\n",
        "                tf.nn.softmax(t_pred / temperature, axis=1),\n",
        "                tf.nn.softmax(s_pred_1 / temperature, axis=1),\n",
        "            )\n",
        "            loss = alpha * student_loss + (1 - alpha) * distillation_loss\n",
        "        \n",
        "        vars = s_model_1.trainable_variables\n",
        "        grad = tape.gradient(loss, vars)\n",
        "        opt.apply_gradients(zip(grad, vars))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            s_pred_2 = s_model_2(x_train[batch_num])\n",
        "            student_loss = s_loss(y_train[batch_num], s_pred_2)\n",
        "        vars = s_model_2.trainable_variables\n",
        "        grad = tape.gradient(student_loss, vars)\n",
        "        opt.apply_gradients(zip(grad, vars))\n",
        "\n",
        "    print(\"epoch {}\".format(e)) \n",
        "    print(\"선생님께 배운 경우\") \n",
        "    s_model_1.evaluate(x_test, y_test)\n",
        "    print(\"혼자 공부한 경우\")\n",
        "    s_model_2.evaluate(x_test, y_test)\n",
        "    print(\"\\n\")      "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDReVc1drSjw",
        "outputId": "20b7f066-b7be-4091-a599-e3a4e95e2e26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 0\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.4531 - sparse_categorical_accuracy: 0.9078\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 0.3678 - sparse_categorical_accuracy: 0.8989\n",
            "\n",
            "\n",
            "epoch 1\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4473 - sparse_categorical_accuracy: 0.9102\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3301 - sparse_categorical_accuracy: 0.9100\n",
            "\n",
            "\n",
            "epoch 2\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 0s 2ms/step - loss: 0.5328 - sparse_categorical_accuracy: 0.8983\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3676 - sparse_categorical_accuracy: 0.8969\n",
            "\n",
            "\n",
            "epoch 3\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 0s 2ms/step - loss: 0.4953 - sparse_categorical_accuracy: 0.9028\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3572 - sparse_categorical_accuracy: 0.9034\n",
            "\n",
            "\n",
            "epoch 4\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4493 - sparse_categorical_accuracy: 0.9107\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3279 - sparse_categorical_accuracy: 0.9095\n",
            "\n",
            "\n",
            "epoch 5\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.5337 - sparse_categorical_accuracy: 0.9039\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3703 - sparse_categorical_accuracy: 0.9001\n",
            "\n",
            "\n",
            "epoch 6\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4813 - sparse_categorical_accuracy: 0.9132\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3355 - sparse_categorical_accuracy: 0.9158\n",
            "\n",
            "\n",
            "epoch 7\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4987 - sparse_categorical_accuracy: 0.9085\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 0s 2ms/step - loss: 0.3529 - sparse_categorical_accuracy: 0.9072\n",
            "\n",
            "\n",
            "epoch 8\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.4646 - sparse_categorical_accuracy: 0.9129\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.3523 - sparse_categorical_accuracy: 0.9032\n",
            "\n",
            "\n",
            "epoch 9\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 0s 2ms/step - loss: 0.4821 - sparse_categorical_accuracy: 0.9127\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3372 - sparse_categorical_accuracy: 0.9140\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vZt4I-SorShH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "G_wUrotArSe3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}